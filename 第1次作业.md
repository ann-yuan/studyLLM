# 第1节课——书生·浦语大模型全链路开源开放体系

| **视频链接**                                 | **文档链接**                                           | **笔记&作业**                                                |
| -------------------------------------------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| https://www.bilibili.com/video/BV1Vx421X72D/ | InternLM2 技术报告https://arxiv.org/pdf/2403.17297.pdf | 看**视频做的笔记**（必做）**和**读InternLM2 技术报告做的笔记**（可选）**都写到**同一个笔记文档**，提交一个链接 |

## 大模型的意义及作用

大模型：具有大量参数的人工智能模型，其通过深度学习技术在大规模数据集上进行训练，以实现复杂的任务和功能。大模型之所以被称为“大”，是因为它们拥有的参数数量通常达到数十亿甚至数万亿个，远远超过传统的人工智能模型。

专用模型：针对特定任务，一个模型解决一个问题

e.g : 图像识别、语音识别等

优势：它们能够针对特定任务提供高度精确的输出

劣势：它们的应用范围相对有限，一旦任务发生变化，可能需要重新训练或调整模型。

通用大模型：一个模型应对多种任务、多种模态

e.g : 文字到文字、图片到文字、文字到图片、文字到视频、视频到文字、图片到视频

优势：其广泛的适用性和灵活性，让它们能够在多种不同的任务和场景中发挥作用，而不需要为每个新任务都设计一个全新的模型。

劣势：通用大模型可能在特定任务上的性能不如专门为该任务设计的专用模型。

选一个开源大模型，用户可以根据自己的实际场景和需求来定制

## 从模型到应用典型流程

**模型选型（评测）**

**业务场景的复杂程度**：

首先，评估自己的业务场景是否复杂。复杂性可能来自于任务的多样性、数据的规模、模型的交互需求等方面。

​	(1) *是 ——> 算力足够吗？*

**算力需求**：

如果业务场景复杂，接下来需要考虑是否有足够的算力资源来支持模型的训练和运行。算力资源包括GPU、TPU等硬件资源以及相应的软件支持。

​		(1.1) *是 ——> 续训/全参数微调 ——> 是否需要环境交互*

​									(1.1.1) *是 ——> 构建智能体*

​									(1.1.2) *否 ——> 模型评测 ——> 模型部署*

**续训/全参数微调 vs 部分参数微调**：

- 如果算力充足，可以选择续训（继续训练）或全参数微调，这意味着在已有预训练模型的基础上，进一步调整模型以适应特定的业务需求。
- 如果算力有限，可能需要采用部分参数微调，这通常涉及到调整模型中较小的部分，以减少计算资源的需求。

​		(1.2) *否 ——> 部分参数微调 ——> 是否需要环境交互*

​									(1.2.1) *是 ——> 构建智能体*

​									(1.2.2) *否 ——> 模型评测 ——> 模型部署*

**环境交互**：

- 根据模型是否需要与环境进行交互（例如，实时响应用户输入或适应动态变化的环境），决定是构建智能体还是直接进行模型评测和部署。
- 如果需要交互，那么构建智能体是必要的，这可能包括开发用户界面、集成传感器输入等。
- 如果不需要交互，可以直接进行模型评测和部署。

​	(2) *否 ——> 模型评测 ——> 模型部署*

**模型评测**：

- 在模型部署之前，需要对模型进行详细的评测，以确保其性能满足业务需求。这可能包括准确性、响应时间、鲁棒性等方面的评估。

**模型部署**：

- 一旦模型通过评测，就可以将其部署到实际的应用环境中。这可能涉及到模型的优化、容器化、云服务部署等步骤。

### 手语机器翻译——研究角度：

1. **评估业务复杂性**：
   - 分析手语机器翻译任务的复杂性。考虑手语的多样性、视频数据的质量、所需的翻译准确性和实时性等。
2. **确定算力资源**：
   - 根据任务的复杂性评估所需的算力资源。手语机器翻译可能需要处理大量的数据，并使用复杂的深度学习模型，因此需要足够的计算能力。
3. **选择模型训练策略**：
   - 如果算力充足，可以选择续训或全参数微调预训练模型。
   - 如果算力有限，可能需要进行部分参数微调，或者使用更轻量级的模型。
4. **集成环境交互**：
   - 如果应用需要实时交互，例如用户通过手语与系统交流，需要构建一个智能体，这可能涉及到开发实时视频处理和反馈系统。
   - 如果应用不需要实时交互，可以继续进行模型评测和部署。
5. **模型评测**：
   - 在模型部署之前，对其进行全面评测。这包括对手语识别的准确性、翻译的流畅性和自然性、以及模型对不同手语风格的适应性进行评估。
   - 可以使用标准的手语数据集，或者创建自己的评估集，以确保模型在各种条件下的性能。
6. **模型部署**：
   - 一旦模型通过评测，可以将其部署到实际应用中。这可能包括开发用户友好的界面、集成到现有的通讯平台或应用程序中，以及确保模型的稳定性和可扩展性。

![image](https://github.com/ann-yuan/studyLLM/blob/main/firstllm1.png)

## 从模型到应用典型流程 —— 准备到落地

**数据**：数据是训练大模型的基础。收集和准备高质量的数据集对于模型的性能至关重要。数据需要经过清洗、标注和预处理，以便模型能够从中学习到有用的特征和模式。

**预训练**：预训练是在大规模数据集上进行的无监督学习过程。在这个阶段，模型通过学习数据的通用特征和结构，获得对语言、图像或其他模态的基本理解。预训练可以提高模型的泛化能力，并为后续的微调阶段打下基础。

**微调**：微调是在特定任务上对预训练模型进行进一步训练的过程。在这个阶段，模型通过学习任务相关的数据集，调整其参数以适应特定的应用场景。微调可以是全参数的，也可以是只针对模型的一部分参数。

​	**增量续训**：（全量参数微调）

​		使用场景——让基座模型学到一些新知识，如某个垂类领域知识。

​		训练数据：文章、书籍、代码等。

​	**有监督微调**：（部分参数微调）

​		使用场景：让模型学会理解各种指令进行对话，或者注入少量领域知识。

​		训练数据：高质量的对话、问答数据。

​	**使用微调框架：XTuner** —— 提高模型针对特定任务的性能。

​	有一台功能强大的汽车，它在出厂时已经具备了很好的性能，但为了适应特定的赛道，可能需要调整它的引擎、悬挂系统等部件。

​	预训练模型就像是那台汽车，而XTuner框架则是提供工具箱，里面包含了各种工具，可以调整和优化模型。

1. **超参数优化**：这就像是调整汽车的引擎设置，以确保它在赛道上能够发挥最佳性能。
2. **模型结构调整**：类似于改装汽车的部件，比如更换轮胎或调整悬挂，以便汽车更好地适应不同的路况。
3. **数据增强**：可以比作对汽车进行风洞测试，通过模拟各种驾驶条件来提高汽车在实际比赛中的稳定性和可靠性。
4. **正则化和泛化**：就像是对汽车进行平衡测试，确保它在各种不同的驾驶环境中都能保持稳定。
5. **性能监控**：这就像是安装在汽车上的传感器和监控系统，能够实时了解汽车的性能状态，并在必要时进行调整。
6. **部署和集成**：最后，将调整好的汽车运送到赛道上，并确保它能够在比赛中顺利运行。

**部署**：部署是将训练好的模型放入实际应用环境中的过程。这可能涉及到模型的优化、压缩和转换，以适应不同的运行环境和设备。部署还需要考虑模型的可扩展性和维护性。

​	**使用智能体框架Lagent**：一套工具和指导手册，帮助构建和编程机器人（一个小型的、智能的机器人，它能够理解周围的环境，做出决策，并采取行动）。

​	**使用多模态智能体工具箱AgentLego**：提供了一套用于构建和训练能够在多模态环境中运行的智能体的组件和接口，同时能够处理和理解多种类型数据（如文本、图像、声音等）的人工智能系统。	

![image](https://github.com/ann-yuan/studyLLM/blob/main/firstllm2.png)

![image](https://github.com/ann-yuan/studyLLM/blob/main/firstllm3.png)

**评测**：评测是评估模型性能的过程。通过一系列的测试和验证，可以了解模型在特定任务上的表现。评测通常使用一系列的指标，如准确率、召回率、F1分数等，以全面了解模型的优缺点。

**应用**：应用是将模型用于实际问题的最终阶段。在这个阶段，模型被集成到产品和服务中，为用户提供价值。应用还需要考虑用户体验、安全性和合规性等因素。
